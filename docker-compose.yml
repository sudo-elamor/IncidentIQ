services:
  api:
    build: ./system/api
    container_name: api
    ports:
      - "8000:8000"
    command: uvicorn app.main:app --host 0.0.0.0 --port 8000

  feeder:
    build: ./feeder
    container_name: feeder
    depends_on:
      - api
    environment:
      LOG_MODE: http
      HTTP_ENDPOINT: http://api:8000/logs/ingest
      HTTP_TIMEOUT: 5
  

  broker:
    image: redis:7-alpine
    container_name: broker
    environment:
      - PROMETHEUS_MULTIPROC_DIR=/tmp/prometheus
      - PROMETHEUS_PORT=8001
    ports:
      - "6379:6379"
    volumes:
      - redis_data:/data
    command: ["redis-server", "--appendonly", "yes"]
    restart: unless-stopped

  worker:
    build: ./system/worker
    depends_on:
      - broker
    container_name: worker
    ports:
      - "8001:8001"
  
  agent:
    build: ./system/agent
    container_name: agent
    depends_on:
      - broker
    environment:
      LLM_BASE_URL: http://llm:8002
  
  llm:
    build: ./system/llm
    container_name: llm
    depends_on:
      - ollama
    environment:
      OLLAMA_BASE_URL: http://ollama:11434
      OLLAMA_MODEL: llama3.2:3b
    ports:
      - "8002:8002"
    restart: unless-stopped
  
  ollama:
    image: ollama/ollama:latest
    container_name: ollama
    environment:
      OLLAMA_MODEL: "llama3.2:3b"
    ports:
      - "11434:11434"
    volumes:
      - ollama_data:/root/.ollama
    restart: unless-stopped


  prometheus:
    image: prom/prometheus
    container_name: prometheus
    volumes:
      - ./infra/prometheus/prometheus.yml:/etc/prometheus/prometheus.yml
    ports:
      - "9090:9090"
  
  grafana:
    image: grafana/grafana:latest
    container_name: grafana
    ports:
      - "3000:3000"
    depends_on:
      - prometheus


volumes:
  redis_data:
  ollama_data: